{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Import keras components\n",
    "from tensorflow import keras\n",
    "from keras import layers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>study_hours</th>\n",
       "      <th>attendance_rate</th>\n",
       "      <th>previous_scores</th>\n",
       "      <th>parental_education</th>\n",
       "      <th>school_type</th>\n",
       "      <th>extracurricular</th>\n",
       "      <th>final_math_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Male</td>\n",
       "      <td>17</td>\n",
       "      <td>9.1</td>\n",
       "      <td>68.7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Bachelor’s</td>\n",
       "      <td>Private</td>\n",
       "      <td>3</td>\n",
       "      <td>86.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Female</td>\n",
       "      <td>17</td>\n",
       "      <td>10.5</td>\n",
       "      <td>66.6</td>\n",
       "      <td>84.8</td>\n",
       "      <td>Bachelor’s</td>\n",
       "      <td>Public</td>\n",
       "      <td>3</td>\n",
       "      <td>90.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Male</td>\n",
       "      <td>17</td>\n",
       "      <td>17.4</td>\n",
       "      <td>58.8</td>\n",
       "      <td>73.8</td>\n",
       "      <td>High School</td>\n",
       "      <td>Private</td>\n",
       "      <td>3</td>\n",
       "      <td>94.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Male</td>\n",
       "      <td>17</td>\n",
       "      <td>8.1</td>\n",
       "      <td>80.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>82.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>17.7</td>\n",
       "      <td>73.8</td>\n",
       "      <td>51.1</td>\n",
       "      <td>Master’s</td>\n",
       "      <td>Public</td>\n",
       "      <td>2</td>\n",
       "      <td>98.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id  gender  age  study_hours  attendance_rate  previous_scores  \\\n",
       "0        1001    Male   17          9.1             68.7             70.0   \n",
       "1        1002  Female   17         10.5             66.6             84.8   \n",
       "2        1003    Male   17         17.4             58.8             73.8   \n",
       "3        1004    Male   17          8.1             80.4             45.0   \n",
       "4        1005    Male   18         17.7             73.8             51.1   \n",
       "\n",
       "  parental_education school_type  extracurricular  final_math_score  \n",
       "0         Bachelor’s     Private                3              86.2  \n",
       "1         Bachelor’s      Public                3              90.6  \n",
       "2        High School     Private                3              94.1  \n",
       "3        High School      Public                1              82.9  \n",
       "4           Master’s      Public                2              98.6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train = pd.read_csv('kbtu-data-science-challenge-2025-entry-task-new/train.csv')\n",
    "\n",
    "all_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor setup\n",
    "\n",
    "target = 'final_math_score'\n",
    "features = ['gender', 'age', 'study_hours', 'attendance_rate', \n",
    "            'previous_scores', 'parental_education', 'school_type', 'extracurricular']\n",
    "\n",
    "num_cols = ['age', 'study_hours', 'attendance_rate', 'previous_scores', 'extracurricular']\n",
    "cat_cols = ['gender', 'parental_education', 'school_type']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first'))\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training shape: (2343, 9)\n"
     ]
    }
   ],
   "source": [
    "train = all_train[all_train[target] < 100]\n",
    "\n",
    "x = preprocessor.fit_transform(train[features])\n",
    "y = train[target]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Processed training shape:\", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qonus/anaconda3/envs/py310/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">337</span> (1.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m337\u001b[0m (1.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">337</span> (1.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m337\u001b[0m (1.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_regression_model(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        # keras.Input(shape=(input_dim,)),\n",
    "        layers.Dense(16, activation='relu', input_dim=input_dim),\n",
    "        # layers.Dropout(0.2),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(4, activation='relu'),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "input_dim_reg = x_train.shape[1]\n",
    "regressor = build_regression_model(input_dim_reg)\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.6391 - mse: 21.6391 - val_loss: 21.1605 - val_mse: 21.1605\n",
      "Epoch 2/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.8418 - mse: 21.8418 - val_loss: 20.9685 - val_mse: 20.9685\n",
      "Epoch 3/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.0928 - mse: 21.0928 - val_loss: 21.1908 - val_mse: 21.1908\n",
      "Epoch 4/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.6292 - mse: 21.6292 - val_loss: 20.9960 - val_mse: 20.9960\n",
      "Epoch 5/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.8658 - mse: 20.8658 - val_loss: 21.3302 - val_mse: 21.3302\n",
      "Epoch 6/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.9442 - mse: 21.9442 - val_loss: 21.2081 - val_mse: 21.2081\n",
      "Epoch 7/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.4768 - mse: 21.4768 - val_loss: 21.1337 - val_mse: 21.1337\n",
      "Epoch 8/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.9028 - mse: 19.9028 - val_loss: 20.9315 - val_mse: 20.9315\n",
      "Epoch 9/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.9980 - mse: 22.9980 - val_loss: 20.9574 - val_mse: 20.9574\n",
      "Epoch 10/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.2979 - mse: 21.2979 - val_loss: 20.8210 - val_mse: 20.8210\n",
      "Epoch 11/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.0519 - mse: 21.0519 - val_loss: 21.1099 - val_mse: 21.1099\n",
      "Epoch 12/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.4297 - mse: 20.4297 - val_loss: 21.2240 - val_mse: 21.2240\n",
      "Epoch 13/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.2752 - mse: 21.2752 - val_loss: 21.2230 - val_mse: 21.2230\n",
      "Epoch 14/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.5953 - mse: 22.5953 - val_loss: 20.7676 - val_mse: 20.7676\n",
      "Epoch 15/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.4984 - mse: 20.4984 - val_loss: 20.8827 - val_mse: 20.8827\n",
      "Epoch 16/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.2073 - mse: 22.2073 - val_loss: 20.9862 - val_mse: 20.9862\n",
      "Epoch 17/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.5923 - mse: 20.5923 - val_loss: 20.7812 - val_mse: 20.7812\n",
      "Epoch 18/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.2844 - mse: 21.2844 - val_loss: 21.0080 - val_mse: 21.0080\n",
      "Epoch 19/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.2394 - mse: 22.2394 - val_loss: 21.6504 - val_mse: 21.6504\n",
      "Epoch 20/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.4958 - mse: 20.4958 - val_loss: 20.9766 - val_mse: 20.9766\n",
      "Epoch 21/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.6338 - mse: 21.6338 - val_loss: 21.1113 - val_mse: 21.1113\n",
      "Epoch 22/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.5946 - mse: 21.5946 - val_loss: 21.1374 - val_mse: 21.1374\n",
      "Epoch 23/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.3825 - mse: 20.3825 - val_loss: 21.1254 - val_mse: 21.1254\n",
      "Epoch 24/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.8219 - mse: 20.8219 - val_loss: 21.1107 - val_mse: 21.1107\n",
      "Epoch 25/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.8402 - mse: 20.8402 - val_loss: 21.6987 - val_mse: 21.6987\n",
      "Epoch 26/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.2015 - mse: 22.2015 - val_loss: 23.2143 - val_mse: 23.2143\n",
      "Epoch 27/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.6198 - mse: 22.6198 - val_loss: 21.0053 - val_mse: 21.0053\n",
      "Epoch 28/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.6996 - mse: 21.6996 - val_loss: 21.1671 - val_mse: 21.1671\n",
      "Epoch 29/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.3013 - mse: 20.3013 - val_loss: 21.1530 - val_mse: 21.1530\n",
      "Epoch 30/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.4527 - mse: 21.4527 - val_loss: 21.5922 - val_mse: 21.5922\n",
      "Epoch 31/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.1123 - mse: 22.1123 - val_loss: 21.3535 - val_mse: 21.3535\n",
      "Epoch 32/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.2968 - mse: 21.2968 - val_loss: 21.7640 - val_mse: 21.7640\n",
      "Epoch 33/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.6713 - mse: 21.6713 - val_loss: 21.2597 - val_mse: 21.2597\n",
      "Epoch 34/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.3780 - mse: 20.3780 - val_loss: 21.1365 - val_mse: 21.1365\n",
      "Epoch 35/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.4208 - mse: 20.4208 - val_loss: 22.2123 - val_mse: 22.2123\n",
      "Epoch 36/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.1576 - mse: 22.1576 - val_loss: 21.0076 - val_mse: 21.0076\n",
      "Epoch 37/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.7511 - mse: 21.7511 - val_loss: 21.1669 - val_mse: 21.1669\n",
      "Epoch 38/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.8050 - mse: 20.8050 - val_loss: 21.1421 - val_mse: 21.1421\n",
      "Epoch 39/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.0147 - mse: 22.0147 - val_loss: 20.9053 - val_mse: 20.9053\n",
      "Epoch 40/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.4937 - mse: 20.4937 - val_loss: 20.7756 - val_mse: 20.7756\n",
      "Epoch 41/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.1371 - mse: 22.1371 - val_loss: 20.9746 - val_mse: 20.9746\n",
      "Epoch 42/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.3026 - mse: 20.3026 - val_loss: 21.0309 - val_mse: 21.0309\n",
      "Epoch 43/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.5448 - mse: 21.5448 - val_loss: 22.0076 - val_mse: 22.0076\n",
      "Epoch 44/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.7680 - mse: 20.7680 - val_loss: 21.2290 - val_mse: 21.2290\n",
      "Epoch 45/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.5846 - mse: 20.5846 - val_loss: 21.3385 - val_mse: 21.3385\n",
      "Epoch 46/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.9946 - mse: 20.9946 - val_loss: 21.1798 - val_mse: 21.1798\n",
      "Epoch 47/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.8077 - mse: 21.8077 - val_loss: 21.2555 - val_mse: 21.2555\n",
      "Epoch 48/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.9269 - mse: 21.9269 - val_loss: 21.1691 - val_mse: 21.1691\n",
      "Epoch 49/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.1108 - mse: 21.1108 - val_loss: 21.0741 - val_mse: 21.0741\n",
      "Epoch 50/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.2650 - mse: 21.2650 - val_loss: 21.6088 - val_mse: 21.6088\n",
      "Epoch 51/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.1974 - mse: 21.1974 - val_loss: 20.9845 - val_mse: 20.9845\n",
      "Epoch 52/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.0216 - mse: 22.0216 - val_loss: 21.2805 - val_mse: 21.2805\n",
      "Epoch 53/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.5232 - mse: 21.5232 - val_loss: 21.1819 - val_mse: 21.1819\n",
      "Epoch 54/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.3570 - mse: 20.3570 - val_loss: 21.1361 - val_mse: 21.1361\n",
      "Epoch 55/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.7415 - mse: 20.7415 - val_loss: 21.2046 - val_mse: 21.2046\n",
      "Epoch 56/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.5948 - mse: 20.5948 - val_loss: 21.2272 - val_mse: 21.2272\n",
      "Epoch 57/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.7061 - mse: 20.7061 - val_loss: 23.0160 - val_mse: 23.0160\n",
      "Epoch 58/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.7391 - mse: 20.7391 - val_loss: 21.8551 - val_mse: 21.8551\n",
      "Epoch 59/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.8170 - mse: 20.8170 - val_loss: 21.1316 - val_mse: 21.1316\n",
      "Epoch 60/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.1476 - mse: 21.1476 - val_loss: 21.3495 - val_mse: 21.3495\n",
      "Epoch 61/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.7052 - mse: 21.7052 - val_loss: 21.3579 - val_mse: 21.3579\n",
      "Epoch 62/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.9568 - mse: 19.9568 - val_loss: 21.2901 - val_mse: 21.2901\n",
      "Epoch 63/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.3419 - mse: 20.3419 - val_loss: 21.1422 - val_mse: 21.1422\n",
      "Epoch 64/300\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.2572 - mse: 21.2572 - val_loss: 21.4512 - val_mse: 21.4512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Sequential name=sequential_3, built=True>,\n",
       " <keras.src.callbacks.history.History at 0x7f015cda0070>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_regressor(model):\n",
    "    early_stop_reg = callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "    history_reg = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=300,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop_reg],\n",
    "        verbose=1\n",
    "    )\n",
    "    return (model, history_reg)\n",
    "\n",
    "train_regressor(regressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE (Regression): 20.767602920532227\n"
     ]
    }
   ],
   "source": [
    "val_mse_reg = regressor.evaluate(x_val, y_val, verbose=0)[0]\n",
    "print(\"Validation MSE (Regression):\", val_mse_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE (Regression): 20.36351203918457\n"
     ]
    }
   ],
   "source": [
    "# regressor.save('models/regressor.keras')\n",
    "\n",
    "model = keras.models.load_model('models/regressor.keras')\n",
    "\n",
    "val_mse_reg = model.evaluate(x_val, y_val, verbose=0)[0]\n",
    "print(\"Validation MSE (Regression):\", val_mse_reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
